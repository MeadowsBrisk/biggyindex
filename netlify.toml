[build]
  command = "yarn build"
  publish = ".next"

[build.environment]
  VOTE_WINDOW_HOURS = "24"
  VOTE_HASH_SALT = "24a9935fabe80c4d07f7e06a904bf16ea1e2a67752798c30e762d35685580bf9"
  VOTE_IP_MAX = "500"
  VOTE_DEBUG = "1"
  NODE_VERSION = "20"

[template.environment]
  VOTE_WINDOW_HOURS = "24"
  VOTE_HASH_SALT = "24a9935fabe80c4d07f7e06a904bf16ea1e2a67752798c30e762d35685580bf9"
  VOTE_IP_MAX = "500"
  VOTE_DEBUG = "1"  # Enable verbose vote debug logging during troubleshooting

# Global functions configuration
[functions]
  node_bundler = "esbuild"
  external_node_modules = [
    "axios",
  "http-cookie-agent",
  "agent-base",
    "tough-cookie",
  "node-fetch",
    "@netlify/blobs",
    "@netlify/neon",
    "yargs",
    "p-queue"
  ]


# Local dev: proxy to the already-running Next.js dev server on port 3000
[dev]
  # Proxy to an already-running Next.js dev server on port 3000
  targetPort = 3000
  port = 8888

# Functions (Next.js pages/api are auto-detected)
# Add any specific function configuration overrides here if needed in future.

#[functions."site-index"]
  # Run the indexing function every 10 minutes (on the hour and half past)
  #schedule = "*/15 * * * *"
  # Ensure the raw script & its data file are packaged with the function so spawning works.
  # included_files = [
  #"scripts/indexer/**",
  # Include aggregated supplement so embedAggregates can require it at runtime on Netlify (outdated: exclusively using Blobs rather than FS now)
  #"public/item-crawler/index-supplement.js",
  # If you generate per-run artifacts (debug, items, share-links), you can optionally include them too:
  # "public/item-crawler/**"
 #   ]

### Unified background stages (items and sellers) on separate schedules
#[functions."crawler-items-background"]
  # STAGING cadence: every 5 hours on the hour to avoid overlapping with live (which runs every 4h)
  # Do NOT change to 4h on staging; this is intentionally offset from production.
  #schedule = "0 */5 * * *"
  #node_bundler = "esbuild"
  #included_files = [
  #  "scripts/unified-crawler/**"
  #]
  #[functions."crawler-items-background".environment]
  #CRAWLER_PERSIST = "blobs"
  # Default disabled; enable in Netlify UI when testing or use ?force=1 to trigger manually
  #CRAWLER_UNIFIED_ITEMS = "0"

#[functions."crawler-sellers-background"]
  # STAGING cadence: offset hours chosen to avoid overlapping with live (intentional non-alignment)
  #schedule = "0 2,6,10,13,18,22 * * *"
  #node_bundler = "esbuild"
  #included_files = [
  #  "scripts/unified-crawler/**"
  #]
  #[functions."crawler-sellers-background".environment]
  #CRAWLER_PERSIST = "blobs"
  # Default disabled; enable in Netlify UI when testing or use ?force=1 to trigger manually
  #CRAWLER_UNIFIED_SELLERS = "0"

[functions."crawler-control"]
  # Lightweight control plane for the crawler (set/clear stop flag)
  node_bundler = "esbuild"

##[functions."crawler-index"]
  # STAGING cadence: every 25 minutes to avoid matching live's 15-minute cadence
  #schedule = "*/25 * * * *"
  #node_bundler = "esbuild"
  #included_files = [
  #  "scripts/unified-crawler/**"
  #]
  #[functions."crawler-index".environment]
  #CRAWLER_PERSIST = "blobs"
  ## Set to 1 when ready to cut over from legacy site-index
  #CRAWLER_UNIFIED_INDEX = "0"



# Orchestrator kept for manual triggers/dev; not scheduled to avoid overlap with stage-specific schedules
[functions."crawler-all-markets-background"]
  node_bundler = "esbuild"
  included_files = [
    "scripts/unified-crawler/**"
  ]


[functions."crawler-index-gb"]
  # Run every 30 minutes on the half-hour cadence
  # Cron format: m h dom mon dow
  # */30 in the minutes field = every 30 minutes
  schedule = "*/30 * * * *"
  node_bundler = "esbuild"
  included_files = [
    "scripts/unified-crawler/**"
  ]
## (Removed) Inngest handler configuration and redirects
