[build]
  command = "yarn build"
  publish = ".next"

[build.environment]
  VOTE_WINDOW_HOURS = "24"
  VOTE_HASH_SALT = "24a9935fabe80c4d07f7e06a904bf16ea1e2a67752798c30e762d35685580bf9"
  VOTE_IP_MAX = "500"
  VOTE_DEBUG = "1"
  NODE_VERSION = "20"

[template.environment]
  VOTE_WINDOW_HOURS = "24"
  VOTE_HASH_SALT = "24a9935fabe80c4d07f7e06a904bf16ea1e2a67752798c30e762d35685580bf9"
  VOTE_IP_MAX = "500"
  VOTE_DEBUG = "1"  # Enable verbose vote debug logging during troubleshooting

# Global functions configuration
[functions]
  node_bundler = "esbuild"
  external_node_modules = [
    "axios",
  "http-cookie-agent",
  "agent-base",
    "tough-cookie",
  "node-fetch",
    "@netlify/blobs",
    "@netlify/neon",
    "yargs",
    "p-queue"
  ]


# Local dev: proxy to the already-running Next.js dev server on port 3000
[dev]
  # Proxy to an already-running Next.js dev server on port 3000
  targetPort = 3000
  port = 8888

# Functions (Next.js pages/api are auto-detected)
# Add any specific function configuration overrides here if needed in future.

#[functions."site-index"]
  # Run the indexing function every 10 minutes (on the hour and half past)
  #schedule = "*/15 * * * *"
  # Ensure the raw script & its data file are packaged with the function so spawning works.
  # included_files = [
  #"scripts/indexer/**",
  # Include aggregated supplement so embedAggregates can require it at runtime on Netlify (outdated: exclusively using Blobs rather than FS now)
  #"public/item-crawler/index-supplement.js",
  # If you generate per-run artifacts (debug, items, share-links), you can optionally include them too:
  # "public/item-crawler/**"
 #   ]

[functions."crawler-control"]
  # Lightweight control plane for the crawler (set/clear stop flag)
  node_bundler = "esbuild"

##[functions."crawler-index"]
  # STAGING cadence: every 25 minutes to avoid matching live's 15-minute cadence
  #schedule = "*/25 * * * *"
  #node_bundler = "esbuild"
  #included_files = [
  #  "scripts/unified-crawler/**"
  #]
  #[functions."crawler-index".environment]
  #CRAWLER_PERSIST = "blobs"
  ## Set to 1 when ready to cut over from legacy site-index
  #CRAWLER_UNIFIED_INDEX = "0"



# Lightweight index-only function for all markets (replaces 5 separate market schedules)
# Does NOT run items/sellers/pruning - those have separate schedules
[functions."index-all-markets-background"]
  # Run every 15 minutes on the dot: :00, :15, :30, :45
  schedule = "0,15,30,45 * * * *"
  node_bundler = "esbuild"
  included_files = [
    "scripts/unified-crawler/**"
  ]

# Full orchestrator - for manual triggers only, NOT scheduled
# Runs index + items + sellers + pruning (very intensive)
[functions."crawler-all-markets-background"]
  # NO SCHEDULE - manual trigger only
  node_bundler = "esbuild"
  included_files = [
    "scripts/unified-crawler/**"
  ]


# Individual market indexers - DISABLED in favor of unified orchestrator
# Keeping configuration commented for rollback if needed

#[functions."crawler-index-gb"]
#  # Run every 20 minutes (baseline cadence) on :00, :20, :40
#  schedule = "*/20 * * * *"
#  node_bundler = "esbuild"
#  included_files = [
#    "scripts/unified-crawler/**"
#  ]

# Staggered per-market indexers: each runs every 30 minutes, offset by 1 minute to avoid overlap
#[functions."crawler-index-fr"]
#  # Staggered: every 20 minutes offset at :01, :21, :41 to avoid overlap with GB
#  schedule = "1,21,41 * * * *"
#  node_bundler = "esbuild"
#  included_files = [
#    "scripts/unified-crawler/**"
#  ]

#[functions."crawler-index-de"]
#  # Staggered: every 20 minutes offset at :02, :22, :42
#  schedule = "2,22,42 * * * *"
#  node_bundler = "esbuild"
#  included_files = [
#    "scripts/unified-crawler/**"
#  ]

#[functions."crawler-index-it"]
#  # Staggered: every 20 minutes offset at :03, :23, :43
#  schedule = "3,23,43 * * * *"
#  node_bundler = "esbuild"
#  included_files = [
#    "scripts/unified-crawler/**"
#  ]

#[functions."crawler-index-pt"]
#  # Staggered: every 20 minutes offset at :04, :24, :44
#  schedule = "4,24,44 * * * *"
#  node_bundler = "esbuild"
#  included_files = [
#    "scripts/unified-crawler/**"
#  ]


### Unified background stages (items and sellers) on separate schedules
[functions."crawler-items-background"]
  # Runs at :04 past the hour on 0,4,8,12,16,20 (4 mins after indexer to avoid overlap)
  schedule = "4 0,4,8,12,16,20 * * *"
  node_bundler = "esbuild"
  included_files = [
    "scripts/unified-crawler/**"
  ]
  #[functions."crawler-items-background".environment]
  #CRAWLER_PERSIST = "blobs"

  
[functions."crawler-sellers-background"]
  # Runs at :04 past the hour on 2,6,10,14,18,22 (4 mins after indexer to avoid overlap)
  schedule = "4 2,6,10,14,18,22 * * *"
  node_bundler = "esbuild"
  included_files = [
    "scripts/unified-crawler/**"
  ]

# Redirects for legacy localized item/seller paths (301 permanent redirects)
[[redirects]]
  from = "/produit/:ref"
  to = "/item/:ref"
  status = 301
  force = true

[[redirects]]
  from = "/produkt/:ref"
  to = "/item/:ref"
  status = 301
  force = true

[[redirects]]
  from = "/prodotto/:ref"
  to = "/item/:ref"
  status = 301
  force = true

[[redirects]]
  from = "/produto/:ref"
  to = "/item/:ref"
  status = 301
  force = true

[[redirects]]
  from = "/vendeur/:id"
  to = "/seller/:id"
  status = 301
  force = true

[[redirects]]
  from = "/verkaeufer/:id"
  to = "/seller/:id"
  status = 301
  force = true

[[redirects]]
  from = "/venditore/:id"
  to = "/seller/:id"
  status = 301
  force = true

[[redirects]]
  from = "/vendedor/:id"
  to = "/seller/:id"
  status = 301
  force = true

# Cache Control for static assets (Cloudflare CDN)
[[headers]]
  for = "/assets/*"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"
    CDN-Cache-Control = "max-age=31536000"

[[headers]]
  for = "/fonts/*"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"
    CDN-Cache-Control = "max-age=31536000"

[[headers]]
  for = "/images/*"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"
    CDN-Cache-Control = "max-age=31536000"

# Next.js static chunks (Cloudflare CDN)
[[headers]]
  for = "/_next/static/*"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"
    CDN-Cache-Control = "max-age=31536000"

